{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Library dan File Unloading\n",
        "Langkah pertama yang harus kita lakukan adalah melakukan import library yang dibutuhkan untuk pengerjaan project ini dan melakukan pembacaan dataset.\n",
        "\n",
        "Notes :\n",
        "\n",
        "Library yang akan kita gunakan adalah pandas (as pd) dan numpy (as np)\n",
        "Dataset yang akan digunakan adalah title.basics.tsv dan title.ratings.tsv\n",
        "Akses dataset :\n",
        "\n",
        "title.basic.tsv = https://storage.googleapis.com/dqlab-dataset/title.basics.tsv\n",
        "title.ratings.tsv = https://storage.googleapis.com/dqlab-dataset/title.ratings.tsv"
      ],
      "metadata": {
        "id": "vaH-MnhxxA85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import library yang dibutuhkan\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "#lakukan pembacaan dataset\n",
        "movie_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/title.basics.tsv', sep='\\t') #untuk menyimpan title_basics.tsv\n",
        "rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/title.ratings.tsv', sep='\\t') #untuk menyimpan title.ratings.tsv"
      ],
      "metadata": {
        "id": "9_uoWIaIxDu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 Data teratas dari table movie\n",
        "Hal pertama yang akan kita lakukan adalah menampilkan 5 data teratas yang ada pada table movie (movie_df). "
      ],
      "metadata": {
        "id": "hgLftFbUxNN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvtkLHqhxPal",
        "outputId": "90b8143a-158a-4ab3-e817-f8f1d8743a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      tconst  titleType                                      primaryTitle  \\\n",
            "0  tt0221078      short                         Circle Dance, Ute Indians   \n",
            "1  tt8862466  tvEpisode  ¡El #TeamOsos va con todo al \"Reality del amor\"!   \n",
            "2  tt7157720  tvEpisode                                     Episode #3.41   \n",
            "3  tt2974998  tvEpisode                         Episode dated 16 May 1987   \n",
            "4  tt2903620  tvEpisode                  Frances Bavier: Aunt Bee Retires   \n",
            "\n",
            "                                      originalTitle  isAdult startYear  \\\n",
            "0                         Circle Dance, Ute Indians        0      1898   \n",
            "1  ¡El #TeamOsos va con todo al \"Reality del amor\"!        0      2018   \n",
            "2                                     Episode #3.41        0      2016   \n",
            "3                         Episode dated 16 May 1987        0      1987   \n",
            "4                  Frances Bavier: Aunt Bee Retires        0      1973   \n",
            "\n",
            "  endYear runtimeMinutes             genres  \n",
            "0      \\N             \\N  Documentary,Short  \n",
            "1      \\N             \\N       Comedy,Drama  \n",
            "2      \\N             29   Comedy,Game-Show  \n",
            "3      \\N             \\N               News  \n",
            "4      \\N             \\N        Documentary  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Info Data dari Setiap Kolom\n",
        "Setelah berhasil menampilkan 5 data teratas yang ada pada table movie (movie_df), hal selanjutnya yang akan kita lakukan adalah melakukan pengecekan tipe data dan informasi lainnya dari setiap kolom yang ada pada table movie (movie_df) tersebut."
      ],
      "metadata": {
        "id": "OQdp47q4xdU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beC8f0GfxjMH",
        "outputId": "2e14d7b5-73a9-4e8b-e2ad-18bb75a93d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9025 entries, 0 to 9024\n",
            "Data columns (total 9 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   tconst          9025 non-null   object\n",
            " 1   titleType       9025 non-null   object\n",
            " 2   primaryTitle    9011 non-null   object\n",
            " 3   originalTitle   9011 non-null   object\n",
            " 4   isAdult         9025 non-null   int64 \n",
            " 5   startYear       9025 non-null   object\n",
            " 6   endYear         9025 non-null   object\n",
            " 7   runtimeMinutes  9025 non-null   object\n",
            " 8   genres          9014 non-null   object\n",
            "dtypes: int64(1), object(8)\n",
            "memory usage: 634.7+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pengecekan Data dengan Nilai NULL\n",
        "Merupakan suatu hal yang wajib untuk melakukan pengecekan terhadap nilai NULL yang ada di dalam dataset saat melakukan cleaning.\n",
        "\n",
        "Oleh karena itu, hal selanjutnya yang akan kita lakukan adalah melakukan pengecekan apakah ada data bernilai NULL pada masing-masing kolom yang ada pada table movie (movie_df)"
      ],
      "metadata": {
        "id": "8RaBhzWtxusO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KEnO4HPxwo2",
        "outputId": "4125ad3d-c842-408b-e9bb-454f8b34970f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tconst             0\n",
            "titleType          0\n",
            "primaryTitle      14\n",
            "originalTitle     14\n",
            "isAdult            0\n",
            "startYear          0\n",
            "endYear            0\n",
            "runtimeMinutes     0\n",
            "genres            11\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis Kolom dengan data bernilai NULL - part 1\n",
        "Dari hasil pengecekan nilai NULL yang sudah dilakukan sebelumnya, diketahui bahwa kolom primaryTitle dan originalTitle memiliki banyak data yang bernilai NULL.\n",
        "\n",
        "Hal selanjutnya yang akan kita lakukan adalah melakukan pengecekan terhadap bentuk data dari kolom primaryTitle dan originalTitle yang bernilai NULL, apakah salah satu atau kedua kolom yang dimaksud ada data yang bernilai NULL."
      ],
      "metadata": {
        "id": "ZAjbOf6Fx8F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_df.loc[(movie_df['primaryTitle'].isnull()) | (movie_df['originalTitle'].isnull())])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mLJb1tFyC34",
        "outputId": "5c389973-9c76-4185-b792-b1caa48531e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          tconst  titleType primaryTitle originalTitle  isAdult startYear  \\\n",
            "9000  tt10790040  tvEpisode          NaN           NaN        0      2019   \n",
            "9001  tt10891902  tvEpisode          NaN           NaN        0      2020   \n",
            "9002  tt11737860  tvEpisode          NaN           NaN        0      2020   \n",
            "9003  tt11737862  tvEpisode          NaN           NaN        0      2020   \n",
            "9004  tt11737866  tvEpisode          NaN           NaN        0      2020   \n",
            "9005  tt11737872  tvEpisode          NaN           NaN        0      2020   \n",
            "9006  tt11737874  tvEpisode          NaN           NaN        0      2020   \n",
            "9007   tt1971246  tvEpisode          NaN           NaN        0      2011   \n",
            "9008   tt2067043  tvEpisode          NaN           NaN        0      1965   \n",
            "9009   tt4404732  tvEpisode          NaN           NaN        0      2015   \n",
            "9010   tt5773048  tvEpisode          NaN           NaN        0      2015   \n",
            "9011   tt8473688  tvEpisode          NaN           NaN        0      1987   \n",
            "9012   tt8541336  tvEpisode          NaN           NaN        0      2018   \n",
            "9013   tt9824302  tvEpisode          NaN           NaN        0      2016   \n",
            "\n",
            "     endYear runtimeMinutes                genres  \n",
            "9000      \\N             \\N                    \\N  \n",
            "9001      \\N             \\N                 Crime  \n",
            "9002      \\N             \\N  Comedy,Drama,Romance  \n",
            "9003      \\N             \\N  Comedy,Drama,Romance  \n",
            "9004      \\N             \\N  Comedy,Drama,Romance  \n",
            "9005      \\N             \\N                    \\N  \n",
            "9006      \\N             \\N  Comedy,Drama,Romance  \n",
            "9007      \\N             \\N             Biography  \n",
            "9008      \\N             \\N                 Music  \n",
            "9009      \\N             \\N                Comedy  \n",
            "9010      \\N             \\N             Talk-Show  \n",
            "9011      \\N             \\N                 Drama  \n",
            "9012      \\N             \\N    Reality-TV,Romance  \n",
            "9013      \\N             \\N           Documentary  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuang Data dengan Nilai NULL - part 1\n",
        "Setelah melihat hasil sebelumnya, dapat dilihat bahwa semua data tidak memiliki judul dan kita dapat membuang data-data tersebut.\n",
        "\n",
        "Pekerjaan selanjutnya yang akan kita lakukan adalah membuang data dengan nilai NULL tersebut dan melihat jumlah data yang ada setelah data-data bernilai NULL tersebut dibuang. "
      ],
      "metadata": {
        "id": "qtop9bmCyV1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mengupdate movie_df dengan membuang data-data bernilai NULL\n",
        "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]#menampilkan jumlah data setelah data dengan nilai NULL dibuang\n",
        "print(len(movie_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMinaR_ryafG",
        "outputId": "f5ef8da1-ddff-4098-950e-8cde5ac79254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis Kolom dengan data bernilai NULL - part 2\n",
        "Selain kolom 'primaryTitle' dan 'originalTitle',masih terdapat kolom lain yang memiliki data bernilai NULL. Kolom tersebut adalah kolom 'genres'\n",
        "\n",
        "Selanjutnya, kita akan melakukan hal yang sama seperti yang sudah kita lakukan pada kolom 'primaryTitle' dan 'originalTitle'.\n",
        "\n",
        "Lakukan pengecekan terhadap bentuk data dari kolom genres yang bernilai NULL. \n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "IYEgiSVTylIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]\n",
        "\n",
        "print(movie_df.loc[movie_df['genres'].isnull()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_fj7Xt6yqWG",
        "outputId": "1d1a35cb-3532-4040-c7ff-c1b984231c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          tconst  titleType  \\\n",
            "9014  tt10233364  tvEpisode   \n",
            "9015  tt10925142  tvEpisode   \n",
            "9016  tt10970874  tvEpisode   \n",
            "9017  tt11670006  tvEpisode   \n",
            "9018  tt11868642  tvEpisode   \n",
            "9019   tt2347742  tvEpisode   \n",
            "9020   tt3984412  tvEpisode   \n",
            "9021   tt8740950  tvEpisode   \n",
            "9022   tt9822816  tvEpisode   \n",
            "9023   tt9900062  tvEpisode   \n",
            "9024   tt9909210  tvEpisode   \n",
            "\n",
            "                                           primaryTitle originalTitle  \\\n",
            "9014  Rolling in the Deep Dish\\tRolling in the Deep ...             0   \n",
            "9015  The IMDb Show on Location: Star Wars Galaxy's ...             0   \n",
            "9016  Die Bauhaus-Stadt Tel Aviv - Vorbild für die M...             0   \n",
            "9017  ...ein angenehmer Unbequemer...\\t...ein angene...             0   \n",
            "9018  GGN Heavyweight Championship Lungs With Mike T...             0   \n",
            "9019  No sufras por la alergia esta primavera\\tNo su...             0   \n",
            "9020  I'm Not Going to Come Last, I'm Just Going to ...             0   \n",
            "9021  Weight Loss Resolution Restart - Ins & Outs of...             0   \n",
            "9022  Zwischen Vertuschung und Aufklärung - Missbrau...             0   \n",
            "9023  The Direction of Yuu's Love: Hings Aren't Goin...             0   \n",
            "9024  Politik und/oder Moral - Wie weit geht das Ver...             0   \n",
            "\n",
            "      isAdult startYear endYear          runtimeMinutes genres  \n",
            "9014     2019        \\N      \\N              Reality-TV    NaN  \n",
            "9015     2019        \\N      \\N               Talk-Show    NaN  \n",
            "9016     2019        \\N      \\N                      \\N    NaN  \n",
            "9017     1981        \\N      \\N             Documentary    NaN  \n",
            "9018     2020        \\N      \\N               Talk-Show    NaN  \n",
            "9019     2004        \\N      \\N                      \\N    NaN  \n",
            "9020     2014        \\N      \\N              Reality-TV    NaN  \n",
            "9021     2015        \\N      \\N              Reality-TV    NaN  \n",
            "9022     2019        \\N      \\N                      \\N    NaN  \n",
            "9023     1994        \\N      \\N  Animation,Comedy,Drama    NaN  \n",
            "9024     2005        \\N      \\N                      \\N    NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuang Data dengan Nilai NULL - part 2\n",
        "Setelah melihat hasil sebelumnya, dapat dilihat bahwa semua data tidak memiliki judul dan kita dapat membuang data-data tersebut.Pekerjaan selanjutnya yang akan kita lakukan adalah membuang data dengan nilai NULL tersebut dan melihat jumlah data yang ada setelah data-data bernilai NULL tersebut dibuang"
      ],
      "metadata": {
        "id": "CVXfT3vUy3-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mengaupdate movie_df dengan membuang data data bernilai null\n",
        "movie_df = movie_df.loc[movie_df['genres'].notnull()]\n",
        "#menampilkan jumlah data setelah data dengan nilai NULL dibuang\n",
        "print(len(movie_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5cGXrKhzDeA",
        "outputId": "fdeebcaf-3f4a-46d8-bd4f-455d79430024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengubah Nilai '\\\\N'\n",
        "Jika kita perhatikan pada kolom 'startYear' , 'endYear', dan 'runtimeMinutes', terdapat data dengan nilai '\\\\N'\n",
        "\n",
        "'\\\\N' berarti NULL.\n",
        "\n",
        "Hal selanjutnya yang akan kita lakukan adalah mengubah nilai dari \\\\\\N tersebur menjadi np.nan dan melakukan casting kolom startYear, endYear, dan runtimeMinutes menjadi float64."
      ],
      "metadata": {
        "id": "wY6hKqDlztL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mengubah nilai '\\\\N' pada startYear menjadi np.nan dan cast kolomnya menjadi float64\n",
        "movie_df['startYear'] = movie_df['startYear'].replace('\\\\N', np.nan)\n",
        "movie_df['startYear'] = movie_df['startYear'].astype('float64')\n",
        "print(movie_df['startYear'].unique()[:5])#mengubah nilai '\\\\N' pada endYear menjadi np.nan dan cast kolomnya menjadi float64\n",
        "movie_df['endYear'] = movie_df['endYear'].replace('\\\\N', np.nan)\n",
        "movie_df['endYear'] = movie_df['endYear'].astype('float64')\n",
        "print(movie_df['endYear'].unique()[:5])#mengubah nilai '\\\\N' pada runtimeMinutes menjadi np.nan dan cast kolomnya menjadi float64\n",
        "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].replace('\\\\N', np.nan)\n",
        "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].astype('float64')\n",
        "print(movie_df['runtimeMinutes'].unique()[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhUNdgY7zyMY",
        "outputId": "a3f05ea9-66d8-4740-f415-5c150f8296b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1898. 2018. 2016. 1987. 1973.]\n",
            "[  nan 2005. 1955. 2006. 1999.]\n",
            "[nan 29.  7. 23. 85.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengubah nilai genres menjadi list\n",
        "Selanjutnya, kita akan membuat sebuah function yang bernama transform_to_list untuk mengubah nilai genre menjadi list. "
      ],
      "metadata": {
        "id": "R-atKst0z1n3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def transform_to_list(x):\n",
        "    if ',' in x: \n",
        "    #ubah menjadi list apabila ada data pada kolom genre\n",
        "        return x.split(',')\n",
        "    else: \n",
        "    #jika tidak ada data, ubah menjadi list kosong\n",
        "        return []\n",
        "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))"
      ],
      "metadata": {
        "id": "sXcJ5ASwz7MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan 5 data teratas\n",
        "Seperti yang sudah kita lakukan pada table movie (movie_df) sebelumnya, sekarang kita akan menampilkan 5 data teratas dari table ratings (rating_df)"
      ],
      "metadata": {
        "id": "MTHlWxe80MfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rating_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHXKJ2Q80QuH",
        "outputId": "49538676-7f71-43b7-995d-f3efafb635ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      tconst  averageRating  numVotes\n",
            "0  tt0000001            5.6      1608\n",
            "1  tt0000002            6.0       197\n",
            "2  tt0000003            6.5      1285\n",
            "3  tt0000004            6.1       121\n",
            "4  tt0000005            6.1      2050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan info data\n",
        "Selanjutnya, kita akan menampilkan tipe data dan informasi lainnya dari masing-masing kolom yang ada pada table rating (rating_df)"
      ],
      "metadata": {
        "id": "cPjjWrKJ0bEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rating_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzvZzrCV0hc-",
        "outputId": "ed9f47f6-e277-42c7-896b-4644b3528ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1030009 entries, 0 to 1030008\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count    Dtype  \n",
            "---  ------         --------------    -----  \n",
            " 0   tconst         1030009 non-null  object \n",
            " 1   averageRating  1030009 non-null  float64\n",
            " 2   numVotes       1030009 non-null  int64  \n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 23.6+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inner Join table movie dan table rating\n",
        "Mari kita melakukan inner join antara rating_df dan movie_df untuk mendapatkan rating pada setiap film yang tersedia, lalu tampilkan 5 data teratas dan tipe data dari tiap kolom yang ada. "
      ],
      "metadata": {
        "id": "SyVtXjK90kam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lakukan join pada kedua table\n",
        "movie_rating_df = pd.merge(movie_df, rating_df, on='tconst', how='inner')#Tampilkan 5 data teratas\n",
        "print(movie_rating_df.head())#Tampilkan tipe data dari tiap kolom\n",
        "print(movie_rating_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFlm3FKM0u4-",
        "outputId": "65b80aa9-7420-446c-8fae-efce1f6d392a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      tconst  titleType              primaryTitle             originalTitle  \\\n",
            "0  tt0043745      short                 Lion Down                 Lion Down   \n",
            "1  tt0167491      video         Wicked Covergirls         Wicked Covergirls   \n",
            "2  tt6574096  tvEpisode      Shadow Play - Part 2      Shadow Play - Part 2   \n",
            "3  tt6941700  tvEpisode              RuPaul Roast              RuPaul Roast   \n",
            "4  tt7305674      video  UCLA Track & Field Promo  UCLA Track & Field Promo   \n",
            "\n",
            "   isAdult  startYear  endYear  runtimeMinutes genres  averageRating  numVotes  \n",
            "0        0     1951.0      NaN             7.0     []            7.1       459  \n",
            "1        1     1998.0      NaN            85.0     []            5.7         7  \n",
            "2        0     2017.0      NaN            22.0     []            8.5       240  \n",
            "3        0     2017.0      NaN             NaN     []            8.0        11  \n",
            "4        0     2017.0      NaN             NaN     []            9.7         7  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1376 entries, 0 to 1375\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   tconst          1376 non-null   object \n",
            " 1   titleType       1376 non-null   object \n",
            " 2   primaryTitle    1376 non-null   object \n",
            " 3   originalTitle   1376 non-null   object \n",
            " 4   isAdult         1376 non-null   int64  \n",
            " 5   startYear       1376 non-null   float64\n",
            " 6   endYear         26 non-null     float64\n",
            " 7   runtimeMinutes  1004 non-null   float64\n",
            " 8   genres          1376 non-null   object \n",
            " 9   averageRating   1376 non-null   float64\n",
            " 10  numVotes        1376 non-null   int64  \n",
            "dtypes: float64(4), int64(2), object(5)\n",
            "memory usage: 129.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memperkecil ukuran Table\n",
        "Hal selanjutnya yang akan kita lakukan adalah memperkecil ukuran table dengan menghilangkan semua nilai NULL dari kolom startYear dan runtimeMinutes karena tidak masuk akal jikalau film tersebut tidak diketahui kapan tahun rilis dan durasi nya. "
      ],
      "metadata": {
        "id": "jB41NntC0zF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Untuk memastikan bahwa sudah tidak ada lagi nilai NULL\n",
        "print(movie_rating_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDGVR3il0_p1",
        "outputId": "4c1ead27-6e52-48d1-9d41-4409aa66c355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1376 entries, 0 to 1375\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   tconst          1376 non-null   object \n",
            " 1   titleType       1376 non-null   object \n",
            " 2   primaryTitle    1376 non-null   object \n",
            " 3   originalTitle   1376 non-null   object \n",
            " 4   isAdult         1376 non-null   int64  \n",
            " 5   startYear       1376 non-null   float64\n",
            " 6   endYear         26 non-null     float64\n",
            " 7   runtimeMinutes  1004 non-null   float64\n",
            " 8   genres          1376 non-null   object \n",
            " 9   averageRating   1376 non-null   float64\n",
            " 10  numVotes        1376 non-null   int64  \n",
            "dtypes: float64(4), int64(2), object(5)\n",
            "memory usage: 129.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertanyaan 1: Berapa nilai C?\n",
        "Hal pertama yang akan kita cari adalah nilai dari C yang merupakan rata-rata dari averageRating"
      ],
      "metadata": {
        "id": "bPtaEDtv1Mhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_list(x):\n",
        "    if ',' in x: \n",
        "        return x.split(',')\n",
        "    else: \n",
        "        return []\n",
        "\n",
        "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))\n",
        "\n",
        "movie_rating_df = pd.merge(movie_df, rating_df, on='tconst', how='inner')\n",
        "movie_rating_df = movie_rating_df.dropna(subset=['startYear','runtimeMinutes'])\n",
        "\n",
        "C = movie_rating_df['averageRating'].mean()\n",
        "print(C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNyDlzyt1PUm",
        "outputId": "f3ad1bbe-9c16-4bac-8f91-6f718ab45988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.829581673306773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertanyaan 2: Berapa nilai m?\n",
        "Mari kita ambil contoh film dengan numVotes di atas 80% populasi, jadi populasi yang akan kita ambil hanya sebesar 20%. "
      ],
      "metadata": {
        "id": "09f0v-KL1g6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def transform_to_list(x):\n",
        "    if ',' in x: \n",
        "        return x.split(',')\n",
        "    else: \n",
        "        return []\n",
        "\n",
        "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))\n",
        "\n",
        "movie_rating_df = pd.merge(movie_df, rating_df, on='tconst', how='inner')\n",
        "movie_rating_df = movie_rating_df.dropna(subset=['startYear','runtimeMinutes'])\n",
        "\n",
        "m = movie_rating_df['numVotes'].quantile(0.8)\n",
        "print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNk38QeP1n_-",
        "outputId": "4b43e839-dba4-4b0a-8696-4de32aed6a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "229.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertanyaan 3: Bagaimana cara membuat fungsi weighted formula?\n",
        "Selanjutnya kita harus membuat sebuah fungsi dengan menggunakan dataframe sebagai variable. "
      ],
      "metadata": {
        "id": "8crxWEym1sbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_list(x):\n",
        "    if ',' in x: \n",
        "        return x.split(',')\n",
        "    else: \n",
        "        return []\n",
        "\n",
        "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))\n",
        "\n",
        "movie_rating_df = pd.merge(movie_df, rating_df, on='tconst', how='inner')\n",
        "movie_rating_df = movie_rating_df.dropna(subset=['startYear','runtimeMinutes'])\n",
        "\n",
        "def imdb_weighted_rating(df, var=0.8):\n",
        "    v = df['numVotes']\n",
        "    R = df['averageRating']\n",
        "    C = df['averageRating'].mean()\n",
        "    m = df['numVotes'].quantile(var)\n",
        "    df['score'] = (v/(m+v))*R + (m/(m+v))* C #Rumus IMDb \n",
        "    return df['score']\n",
        "    \n",
        "imdb_weighted_rating(movie_rating_df)\n",
        "\n",
        "#melakukan pengecekan dataframe\n",
        "print(movie_rating_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XOhNphs10Wo",
        "outputId": "1e86d825-f576-4ace-ceb2-edfef92e01b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      tconst  titleType          primaryTitle         originalTitle  isAdult  \\\n",
            "0  tt0043745      short             Lion Down             Lion Down        0   \n",
            "1  tt0167491      video     Wicked Covergirls     Wicked Covergirls        1   \n",
            "2  tt6574096  tvEpisode  Shadow Play - Part 2  Shadow Play - Part 2        0   \n",
            "5  tt2262289      movie               The Pin               The Pin        0   \n",
            "6  tt0874027  tvEpisode         Episode #32.9         Episode #32.9        0   \n",
            "\n",
            "   startYear  endYear  runtimeMinutes genres  averageRating  numVotes  \\\n",
            "0     1951.0      NaN             7.0     []            7.1       459   \n",
            "1     1998.0      NaN            85.0     []            5.7         7   \n",
            "2     2017.0      NaN            22.0     []            8.5       240   \n",
            "5     2013.0      NaN            85.0     []            7.7        27   \n",
            "6     2006.0      NaN            29.0     []            8.0         8   \n",
            "\n",
            "      score  \n",
            "0  7.009992  \n",
            "1  6.796077  \n",
            "2  7.684380  \n",
            "5  6.921384  \n",
            "6  6.869089  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertanyaan 4: Bagaimana cara membuat simple recommender system?\n",
        "Dari task yang sudah kita lakukan sebelumnya, telah terdapat field tambahan 'score'.\n",
        "\n",
        "Pertama kita akan filter numVotes yang lebih dari m kemudian diurutkan score dari tertinggi ke terendah untuk diambil nilai beberapa nilai teratas"
      ],
      "metadata": {
        "id": "TPGlFfyv2HZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_list(x):\n",
        "    if ',' in x: \n",
        "        return x.split(',')\n",
        "    else: \n",
        "        return []\n",
        "\n",
        "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))\n",
        "\n",
        "movie_rating_df = pd.merge(movie_df, rating_df, on='tconst', how='inner')\n",
        "movie_rating_df = movie_rating_df.dropna(subset=['startYear','runtimeMinutes'])\n",
        "\n",
        "C = movie_rating_df['averageRating'].mean()\n",
        "m = movie_rating_df['numVotes'].quantile(0.8)\n",
        "\n",
        "def imdb_weighted_rating(df, var=0.8):\n",
        "    v = df['numVotes']\n",
        "    R = df['averageRating']\n",
        "    C = df['averageRating'].mean()\n",
        "    m = df['numVotes'].quantile(var)\n",
        "    df['score'] = (v/(m+v))*R + (m/(m+v))*C\n",
        "    return df['score']\n",
        "    \n",
        "imdb_weighted_rating(movie_rating_df)\n",
        "\n",
        "def simple_recommender(df, top=100):\n",
        "    df = df.loc[df['numVotes'] >= m]\n",
        "    df = df.sort_values(by='score', ascending=False) #urutkan dari nilai tertinggi ke terendah\n",
        "    \n",
        "  #Ambil data 100 teratas\n",
        "    df = df[:top]\n",
        "    return df\n",
        "    \n",
        "#Ambil data 25 teratas     \n",
        "print(simple_recommender(movie_rating_df, top=25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUDgTfOw2NE2",
        "outputId": "a6f29dea-2e3f-47bc-bd47-2e529a5d14aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         tconst  titleType                                   primaryTitle  \\\n",
            "68    tt4110822  tvEpisode                                  S.O.S. Part 2   \n",
            "236   tt2200252      video                    Attack of the Clones Review   \n",
            "1181  tt7697962  tvEpisode            Chapter Seventeen: The Missionaries   \n",
            "326   tt7124590  tvEpisode            Chapter Thirty-Four: Judgment Night   \n",
            "1045  tt0533506  tvEpisode                                       The Prom   \n",
            "71    tt8399426  tvEpisode                                        Savages   \n",
            "1234  tt2843830  tvEpisode                                          VIII.   \n",
            "1087  tt4295140   tvSeries                                   Chef's Table   \n",
            "1054  tt2503932  tvEpisode                                Trial and Error   \n",
            "448   tt0337566      video                       AC/DC: Live at Donington   \n",
            "624   tt0620159  tvEpisode                                     Strike Out   \n",
            "1281  tt3166390  tvEpisode                         Looking for a Plus-One   \n",
            "314   tt0954759  tvEpisode                                   Ben Franklin   \n",
            "189   tt5661506      video            Florence + the Machine: The Odyssey   \n",
            "151   tt3954426  tvEpisode                                Bleeding Kansas   \n",
            "1344  tt6644294  tvEpisode                 The Hostile Hospital: Part Two   \n",
            "1242  tt3677742  tvSpecial  Saturday Night Live: 40th Anniversary Special   \n",
            "1217  tt3642464  tvEpisode                                    Giant Woman   \n",
            "544   tt0734655  tvEpisode                              The Little People   \n",
            "49    tt9119838  tvEpisode                      Parisian Legend Has It...   \n",
            "357   tt4084774  tvEpisode                           Trial and Punishment   \n",
            "1111  tt4174072  tvEpisode                     Immortal Emerges from Cave   \n",
            "790   tt4279086  tvEpisode                       And Santa's Midnight Run   \n",
            "972   tt0048028      movie                                   East of Eden   \n",
            "819   tt0032156      movie            The Story of the Last Chrysanthemum   \n",
            "\n",
            "                                      originalTitle  isAdult  startYear  \\\n",
            "68                                    S.O.S. Part 2        0     2015.0   \n",
            "236                     Attack of the Clones Review        0     2010.0   \n",
            "1181            Chapter Seventeen: The Missionaries        0     2019.0   \n",
            "326             Chapter Thirty-Four: Judgment Night        0     2018.0   \n",
            "1045                                       The Prom        0     1999.0   \n",
            "71                                          Savages        0     2018.0   \n",
            "1234                                          VIII.        0     2014.0   \n",
            "1087                                   Chef's Table        0     2015.0   \n",
            "1054                                Trial and Error        0     2013.0   \n",
            "448                        AC/DC: Live at Donington        0     1992.0   \n",
            "624                                      Strike Out        0     2000.0   \n",
            "1281                         Looking for a Plus-One        0     2014.0   \n",
            "314                                    Ben Franklin        0     2007.0   \n",
            "189             Florence + the Machine: The Odyssey        0     2016.0   \n",
            "151                                 Bleeding Kansas        0     2014.0   \n",
            "1344                 The Hostile Hospital: Part Two        0     2018.0   \n",
            "1242  Saturday Night Live: 40th Anniversary Special        0     2015.0   \n",
            "1217                                    Giant Woman        0     2014.0   \n",
            "544                               The Little People        0     1962.0   \n",
            "49                        Parisian Legend Has It...        0     2019.0   \n",
            "357                            Trial and Punishment        0     2015.0   \n",
            "1111                     Immortal Emerges from Cave        0     2017.0   \n",
            "790                        And Santa's Midnight Run        0     2014.0   \n",
            "972                                    East of Eden        0     1955.0   \n",
            "819                              Zangiku monogatari        0     1939.0   \n",
            "\n",
            "      endYear  runtimeMinutes genres  averageRating  numVotes     score  \n",
            "68        NaN            43.0     []            9.4      3820  9.254624  \n",
            "236       NaN            86.0     []            9.3      1411  8.955045  \n",
            "1181      NaN            54.0     []            9.2      1536  8.892450  \n",
            "326       NaN            42.0     []            9.1      1859  8.850993  \n",
            "1045      NaN            60.0     []            8.9      2740  8.740308  \n",
            "71        NaN            58.0     []            9.0      1428  8.700045  \n",
            "1234      NaN            57.0     []            8.9      1753  8.660784  \n",
            "1087      NaN            50.0     []            8.6     12056  8.566998  \n",
            "1054      NaN            43.0     []            8.6      2495  8.451165  \n",
            "448       NaN           120.0     []            8.5      1343  8.256663  \n",
            "624       NaN            30.0     []            8.7       401  8.020118  \n",
            "1281      NaN            28.0     []            8.7       396  8.014679  \n",
            "314       NaN            21.0     []            8.1      2766  8.002863  \n",
            "189       NaN            49.0     []            8.8       330  7.992798  \n",
            "151       NaN            42.0     []            8.6       437  7.991253  \n",
            "1344      NaN            40.0     []            8.3       812  7.976536  \n",
            "1242      NaN           106.0     []            8.1      1931  7.965312  \n",
            "1217      NaN            11.0     []            8.4       566  7.947641  \n",
            "544       NaN            25.0     []            8.1      1559  7.937290  \n",
            "49        NaN            42.0     []            8.9       263  7.936330  \n",
            "357       NaN            56.0     []            8.8       289  7.928908  \n",
            "1111      NaN            53.0     []            8.0      2898  7.914287  \n",
            "790       NaN            42.0     []            8.2       823  7.901687  \n",
            "972       NaN           118.0     []            7.9     38543  7.893678  \n",
            "819       NaN           143.0     []            7.9      2974  7.823470  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertanyaan 5: Bagaimana cara membuat simple recommender system dengan user preferences?\n",
        "Dari task yang sudah dilakukan sebelumnya, dapat dilihat sekarang daftar film telah diurutkan dari score tertinggi ke terendah.\n",
        "\n",
        "Film dengan averageRating yang tinggi tidak selalu mendapat posisi yang lebih tinggi dibanding film dengan averageRating lebih rendah, hal ini disebabkan karena kita juga memperhitungkan faktor banyaknya votes\n",
        "\n",
        "\n",
        "Sistem rekomendasi ini masih bisa ditingkatkan dengan menambah filter spesifik tentang titleType, startYear, ataupun filter yang lain\n",
        "\n",
        "Pekerjaan selanjutnya yang akan kita lakukan adalah membuat function untuk melakukan filter berdasarkan isAdult, startYear, dan genres. "
      ],
      "metadata": {
        "id": "L1-yWHc_2RzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "movie_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/title.basics.tsv', sep='\\t')\n",
        "rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/title.ratings.tsv', sep='\\t')\n",
        "\n",
        "movie_df = movie_df.loc[(movie_df['primaryTitle'].notnull()) & (movie_df['originalTitle'].notnull())]\n",
        "movie_df = movie_df.loc[movie_df['genres'].notnull()]\n",
        "movie_df['startYear'] = movie_df['startYear'].replace('\\\\N', np.nan)\n",
        "movie_df['startYear'] = movie_df['startYear'].astype('float64')\n",
        "movie_df['endYear'] = movie_df['endYear'].replace('\\\\N', np.nan)\n",
        "movie_df['endYear'] = movie_df['endYear'].astype('float64')\n",
        "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].replace('\\\\N', np.nan)\n",
        "movie_df['runtimeMinutes'] = movie_df['runtimeMinutes'].astype('float64')\n",
        "\n",
        "def transform_to_list(x):\n",
        "    if ',' in x: \n",
        "        return x.split(',')\n",
        "    else: \n",
        "        return []\n",
        "\n",
        "movie_df['genres'] = movie_df['genres'].apply(lambda x: transform_to_list(x))\n",
        "\n",
        "movie_rating_df = pd.merge(movie_df, rating_df, on='tconst', how='inner')\n",
        "movie_rating_df = movie_rating_df.dropna(subset=['startYear','runtimeMinutes'])\n",
        "\n",
        "C = movie_rating_df['averageRating'].mean()\n",
        "m = movie_rating_df['numVotes'].quantile(0.8)\n",
        "\n",
        "def imdb_weighted_rating(df, var=0.8):\n",
        "    v = df['numVotes']\n",
        "    R = df['averageRating']\n",
        "    C = df['averageRating'].mean()\n",
        "    m = df['numVotes'].quantile(var)\n",
        "    df['score'] = (v/(m+v))*R + (m/(m+v))*C\n",
        "    return df['score']\n",
        "    \n",
        "imdb_weighted_rating(movie_rating_df)\n",
        "\n",
        "def simple_recommender(df, top=100):\n",
        "    df = df.loc[df['numVotes'] >= m]\n",
        "    df = df.sort_values(by='score', ascending=False)\n",
        "    \n",
        "    #jika kamu hanya ingin mengambil 100 teratas\n",
        "    df = df[:top]\n",
        "    return df\n",
        "\n",
        "df = movie_rating_df.copy()\n",
        "\n",
        "def user_prefer_recommender(df, ask_adult, ask_start_year, ask_genre, top=100):\n",
        "    if ask_adult.lower() == 'yes':\n",
        "        df = df.loc[df['isAdult'] == 1]\n",
        "    elif ask_adult.lower() == 'no':\n",
        "        df = df.loc[df['isAdult'] == 0]\n",
        "\n",
        "    df = df.loc[df['startYear'] >= int(ask_start_year)]\n",
        "\n",
        "    if ask_genre.lower() == 'all':\n",
        "        df = df\n",
        "    else:\n",
        "        def filter_genre(x):\n",
        "            if ask_genre.lower() in str(x).lower():\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        df = df.loc[df['genres'].apply(lambda x: filter_genre(x))]\n",
        "\n",
        "    df = df.loc[df['numVotes'] >= m]\n",
        "    df = df.sort_values(by='score', ascending=False)\n",
        "    \n",
        "    df = df[:top]\n",
        "    return df\n",
        "\n",
        "print(user_prefer_recommender(df,\n",
        "                       ask_adult = 'no',\n",
        "                        ask_start_year = 2000,\n",
        "                       ask_genre = 'drama'\n",
        "                       ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQtDhzm422Q9",
        "outputId": "a29168a7-c1ab-45c8-8fe7-724bc93d8526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         tconst  titleType                         primaryTitle  \\\n",
            "68    tt4110822  tvEpisode                        S.O.S. Part 2   \n",
            "1181  tt7697962  tvEpisode  Chapter Seventeen: The Missionaries   \n",
            "326   tt7124590  tvEpisode  Chapter Thirty-Four: Judgment Night   \n",
            "71    tt8399426  tvEpisode                              Savages   \n",
            "1234  tt2843830  tvEpisode                                VIII.   \n",
            "1054  tt2503932  tvEpisode                      Trial and Error   \n",
            "1281  tt3166390  tvEpisode               Looking for a Plus-One   \n",
            "151   tt3954426  tvEpisode                      Bleeding Kansas   \n",
            "1344  tt6644294  tvEpisode       The Hostile Hospital: Part Two   \n",
            "357   tt4084774  tvEpisode                 Trial and Punishment   \n",
            "708   tt2751234  tvEpisode                         Resurrection   \n",
            "605   tt9141176  tvEpisode                59 horas desaparecido   \n",
            "983   tt5063116  tvEpisode                                Shell   \n",
            "1017  tt2206822  tvEpisode                      Vested Interest   \n",
            "73    tt0847785  tvEpisode                          Like It Was   \n",
            "625   tt7348490  tvEpisode                   Forced Perspective   \n",
            "1272  tt0534736  tvEpisode                 Sex, Lies and Larvae   \n",
            "800   tt0901201  tvEpisode                           Crossroads   \n",
            "659   tt3909890  tvEpisode                                Moppa   \n",
            "1170  tt0647504  tvEpisode                        Tainted Fruit   \n",
            "1001  tt2129485  tvEpisode                      A Desperate Man   \n",
            "977   tt4391820  tvEpisode                              Aisling   \n",
            "1096  tt6822518      movie                    Yasamak Güzel Sey   \n",
            "910   tt3348270  tvEpisode                            Bloodline   \n",
            "746   tt0534765  tvEpisode                      You've Got Male   \n",
            "299   tt4527626  tvEpisode                His Troubled Thoughts   \n",
            "509   tt1256301  tvEpisode                           Nine Lives   \n",
            "897   tt2349242  tvEpisode                        The Fifth Man   \n",
            "1090  tt0212815      movie                             Big Eden   \n",
            "109   tt1753383      movie                      A Dog's Purpose   \n",
            "550   tt8163822      short                The Neighbors' Window   \n",
            "834   tt6509862      movie                             Mr. Long   \n",
            "600   tt0329002      movie             Hard Goodbyes: My Father   \n",
            "642   tt0993186  tvEpisode                  Daleks in Manhattan   \n",
            "691   tt3663996  tvEpisode                          Storm Watch   \n",
            "727   tt3563898   tvSeries            Brynhildr in the Darkness   \n",
            "164   tt0464049      movie                     The History Boys   \n",
            "893   tt8858104      movie                         Guava Island   \n",
            "927   tt3663990  tvEpisode                                Pilot   \n",
            "462   tt5197828  tvEpisode                                Right   \n",
            "1068  tt8369852  tvEpisode              I Think We're Alone Now   \n",
            "940   tt0396190      movie                     Return to Sender   \n",
            "610   tt3526706      movie                            Chevalier   \n",
            "1126  tt2151739      movie                Meet Me in Montenegro   \n",
            "637   tt0857275      movie                      Wonderful World   \n",
            "385   tt0472259      movie                       Alone with Her   \n",
            "1014  tt1159705      movie                        Teenage Angst   \n",
            "1043  tt5518756      movie                      The Misandrists   \n",
            "1154  tt1386492      movie                  This Is Not a Movie   \n",
            "492   tt0882806      movie                           Sugar Boxx   \n",
            "922   tt2948790      movie                     Return to Sender   \n",
            "690   tt4477536      movie                   Fifty Shades Freed   \n",
            "677   tt8923408  tvEpisode                          #JinnHunter   \n",
            "1039  tt5227468      movie                        Beiimaan Love   \n",
            "1138  tt1126516      movie              Money Hai Toh Honey Hai   \n",
            "1208  tt3044882      movie                                Nasha   \n",
            "1197  tt3016748      movie                       Jacob's Ladder   \n",
            "846   tt0488164      movie                          Moscow Zero   \n",
            "90    tt0299981    tvMovie               Highlander: The Source   \n",
            "\n",
            "                             originalTitle  isAdult  startYear  endYear  \\\n",
            "68                           S.O.S. Part 2        0     2015.0      NaN   \n",
            "1181   Chapter Seventeen: The Missionaries        0     2019.0      NaN   \n",
            "326    Chapter Thirty-Four: Judgment Night        0     2018.0      NaN   \n",
            "71                                 Savages        0     2018.0      NaN   \n",
            "1234                                 VIII.        0     2014.0      NaN   \n",
            "1054                       Trial and Error        0     2013.0      NaN   \n",
            "1281                Looking for a Plus-One        0     2014.0      NaN   \n",
            "151                        Bleeding Kansas        0     2014.0      NaN   \n",
            "1344        The Hostile Hospital: Part Two        0     2018.0      NaN   \n",
            "357                   Trial and Punishment        0     2015.0      NaN   \n",
            "708                           Resurrection        0     2014.0      NaN   \n",
            "605                  59 horas desaparecido        0     2019.0      NaN   \n",
            "983                                  Shell        0     2016.0      NaN   \n",
            "1017                       Vested Interest        0     2012.0      NaN   \n",
            "73                             Like It Was        0     2006.0      NaN   \n",
            "625                     Forced Perspective        0     2018.0      NaN   \n",
            "1272                  Sex, Lies and Larvae        0     2000.0      NaN   \n",
            "800                             Crossroads        0     2006.0      NaN   \n",
            "659                                  Moppa        0     2014.0      NaN   \n",
            "1170                         Tainted Fruit        0     2001.0      NaN   \n",
            "1001                       A Desperate Man        0     2012.0      NaN   \n",
            "977                                Aisling        0     2019.0      NaN   \n",
            "1096                     Yasamak Güzel Sey        0     2017.0      NaN   \n",
            "910                              Bloodline        0     2014.0      NaN   \n",
            "746                        You've Got Male        0     2001.0      NaN   \n",
            "299                  His Troubled Thoughts        0     2016.0      NaN   \n",
            "509                             Nine Lives        0     2008.0      NaN   \n",
            "897                          The Fifth Man        0     2012.0      NaN   \n",
            "1090                              Big Eden        0     2000.0      NaN   \n",
            "109                        A Dog's Purpose        0     2017.0      NaN   \n",
            "550                  The Neighbors' Window        0     2019.0      NaN   \n",
            "834                                Ryu san        0     2017.0      NaN   \n",
            "600   Dyskoloi apohairetismoi: O babas mou        0     2002.0      NaN   \n",
            "642                    Daleks in Manhattan        0     2007.0      NaN   \n",
            "691                            Storm Watch        0     2014.0      NaN   \n",
            "727                  Gokukoku no Brynhildr        0     2014.0      NaN   \n",
            "164                       The History Boys        0     2006.0      NaN   \n",
            "893                           Guava Island        0     2019.0      NaN   \n",
            "927                                  Pilot        0     2014.0      NaN   \n",
            "462                                  Right        0     2016.0      NaN   \n",
            "1068               I Think We're Alone Now        0     2019.0      NaN   \n",
            "940                       Return to Sender        0     2004.0      NaN   \n",
            "610                              Chevalier        0     2015.0      NaN   \n",
            "1126                 Meet Me in Montenegro        0     2014.0      NaN   \n",
            "637                        Wonderful World        0     2009.0      NaN   \n",
            "385                         Alone with Her        0     2006.0      NaN   \n",
            "1014                         Teenage Angst        0     2008.0      NaN   \n",
            "1043                       The Misandrists        0     2017.0      NaN   \n",
            "1154                   This Is Not a Movie        0     2011.0      NaN   \n",
            "492                             Sugar Boxx        0     2009.0      NaN   \n",
            "922                       Return to Sender        0     2015.0      NaN   \n",
            "690                     Fifty Shades Freed        0     2018.0      NaN   \n",
            "677                            #JinnHunter        0     2019.0      NaN   \n",
            "1039                         Beiimaan Love        0     2016.0      NaN   \n",
            "1138               Money Hai Toh Honey Hai        0     2008.0      NaN   \n",
            "1208                                 Nasha        0     2013.0      NaN   \n",
            "1197                        Jacob's Ladder        0     2019.0      NaN   \n",
            "846                            Moscow Zero        0     2006.0      NaN   \n",
            "90                  Highlander: The Source        0     2007.0      NaN   \n",
            "\n",
            "      runtimeMinutes                       genres  averageRating  numVotes  \\\n",
            "68              43.0   [Action, Adventure, Drama]            9.4      3820   \n",
            "1181            54.0     [Drama, Fantasy, Horror]            9.2      1536   \n",
            "326             42.0      [Crime, Drama, Mystery]            9.1      1859   \n",
            "71              58.0    [Drama, Fantasy, Romance]            9.0      1428   \n",
            "1234            57.0           [Adventure, Drama]            8.9      1753   \n",
            "1054            43.0     [Drama, Fantasy, Horror]            8.6      2495   \n",
            "1281            28.0     [Comedy, Drama, Romance]            8.7       396   \n",
            "151             42.0             [Drama, Western]            8.6       437   \n",
            "1344            40.0   [Adventure, Comedy, Drama]            8.3       812   \n",
            "357             56.0           [Adventure, Drama]            8.8       289   \n",
            "708             43.0       [Crime, Drama, Horror]            8.0      1077   \n",
            "605             48.0     [Crime, Drama, Thriller]            8.1       674   \n",
            "983             32.0              [Comedy, Drama]            8.5       275   \n",
            "1017            43.0       [Comedy, Crime, Drama]            8.0       525   \n",
            "73              43.0     [Comedy, Drama, Mystery]            8.1       405   \n",
            "625             43.0      [Crime, Drama, Mystery]            7.9       413   \n",
            "1272            46.0      [Crime, Drama, Mystery]            7.7       689   \n",
            "800             42.0     [Action, Drama, Mystery]            7.7       654   \n",
            "659             27.0              [Comedy, Drama]            7.8       410   \n",
            "1170            98.0      [Crime, Drama, Mystery]            7.7       538   \n",
            "1001            44.0       [Action, Crime, Drama]            7.7       501   \n",
            "977             51.0      [Crime, Drama, Fantasy]            7.5      1558   \n",
            "1096           101.0              [Comedy, Drama]            7.5      1541   \n",
            "910             44.0     [Drama, Horror, Mystery]            7.7       436   \n",
            "746             45.0      [Crime, Drama, Mystery]            7.6       620   \n",
            "299             59.0     [Crime, Drama, Thriller]            7.5       859   \n",
            "509             44.0       [Action, Crime, Drama]            7.6       501   \n",
            "897             44.0       [Action, Crime, Drama]            7.8       270   \n",
            "1090           118.0     [Comedy, Drama, Romance]            7.3      3906   \n",
            "109            100.0   [Adventure, Comedy, Drama]            7.2     61521   \n",
            "550             21.0               [Drama, Short]            7.2      2222   \n",
            "834            129.0       [Action, Crime, Drama]            7.1       960   \n",
            "600            113.0              [Drama, Family]            7.1       423   \n",
            "642             45.0   [Adventure, Drama, Family]            7.0      4982   \n",
            "691             43.0             [Drama, Romance]            7.0       309   \n",
            "727             22.0   [Action, Animation, Drama]            6.8       733   \n",
            "164            109.0     [Comedy, Drama, Romance]            6.8     19858   \n",
            "893             55.0       [Comedy, Drama, Music]            6.7      7935   \n",
            "927             44.0             [Drama, Romance]            6.6       403   \n",
            "462             42.0      [Crime, Drama, Mystery]            6.5       641   \n",
            "1068            43.0  [Adventure, Drama, Mystery]            6.3       563   \n",
            "940            109.0            [Drama, Thriller]            6.4      2342   \n",
            "610            105.0              [Comedy, Drama]            6.3      3890   \n",
            "1126            90.0     [Comedy, Drama, Romance]            5.8       258   \n",
            "637             89.0             [Drama, Romance]            6.1      2288   \n",
            "385             78.0     [Crime, Drama, Thriller]            6.0      3738   \n",
            "1014            64.0            [Drama, Thriller]            5.3       355   \n",
            "1043            91.0              [Comedy, Drama]            5.1       387   \n",
            "1154            99.0              [Comedy, Drama]            4.6       642   \n",
            "492             86.0               [Crime, Drama]            3.5       229   \n",
            "922             92.0            [Drama, Thriller]            5.1     11434   \n",
            "690            105.0   [Drama, Romance, Thriller]            4.5     50572   \n",
            "677             24.0     [Drama, Fantasy, Horror]            3.6       592   \n",
            "1039           120.0   [Drama, Romance, Thriller]            2.8       374   \n",
            "1138           138.0              [Comedy, Drama]            2.8       527   \n",
            "1208           122.0            [Drama, Thriller]            3.2      1132   \n",
            "1197            89.0     [Drama, Horror, Mystery]            3.4      2065   \n",
            "846             82.0      [Action, Drama, Horror]            3.0      1620   \n",
            "90              86.0   [Action, Adventure, Drama]            3.1      8855   \n",
            "\n",
            "         score  \n",
            "68    9.254624  \n",
            "1181  8.892450  \n",
            "326   8.850993  \n",
            "71    8.700045  \n",
            "1234  8.660784  \n",
            "1054  8.451165  \n",
            "1281  8.014679  \n",
            "151   7.991253  \n",
            "1344  7.976536  \n",
            "357   7.928908  \n",
            "708   7.794774  \n",
            "605   7.777823  \n",
            "983   7.741020  \n",
            "1017  7.644528  \n",
            "73    7.641127  \n",
            "625   7.518184  \n",
            "1272  7.482870  \n",
            "800   7.474263  \n",
            "659   7.452229  \n",
            "1170  7.440123  \n",
            "1001  7.426951  \n",
            "977   7.414087  \n",
            "1096  7.413262  \n",
            "910   7.400262  \n",
            "746   7.392196  \n",
            "299   7.358892  \n",
            "509   7.358321  \n",
            "897   7.354658  \n",
            "1090  7.273948  \n",
            "109   7.198626  \n",
            "550   7.165391  \n",
            "834   7.047918  \n",
            "600   7.005022  \n",
            "642   6.992511  \n",
            "691   6.927461  \n",
            "727   6.807042  \n",
            "164   6.800337  \n",
            "893   6.703635  \n",
            "927   6.683187  \n",
            "462   6.586752  \n",
            "1068  6.453124  \n",
            "940   6.438263  \n",
            "610   6.329443  \n",
            "1126  6.284136  \n",
            "637   6.166378  \n",
            "385   6.047889  \n",
            "1014  5.899785  \n",
            "1043  5.742978  \n",
            "1154  5.186193  \n",
            "492   5.164791  \n",
            "922   5.133960  \n",
            "690   4.510501  \n",
            "677   4.500821  \n",
            "1039  4.330305  \n",
            "1138  4.020601  \n",
            "1208  3.810708  \n",
            "1197  3.742360  \n",
            "846   3.474296  \n",
            "90    3.194020  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DEkk0CyC3DBh"
      }
    }
  ]
}